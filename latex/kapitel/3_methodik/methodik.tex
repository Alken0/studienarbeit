% !TEX root = ../../main.tex
% !TeX spellcheck = de_DE

\chapter{Methodik}
In diesem Kapitel werden zunächst Eigenschaften der Trainingsdaten erläutert.
Dabei wird auf die Bildeigenschaften und Besonderheiten der dargestellten Figuren in den Bildern eingegangen.
Danach erfolgt eine Festlegung der Kriterien für ein erfolgreiche trainiertes 'GAN', das Grundlage für spätere Vergleiche von Trainingserfolgen sein wird.

\section{Trainingsdaten}
Bei den Trainingsdaten handelt es sich um synthetisch generierte Bilder mit geometrischen Figuren.
Zwar gibt es bereits Datensätze mit solchen Bildern \cite{dataset:four-shapes, dataset:2d-geometric-shapes-dataset}, im Rahmen der Studienarbeit werden jedoch keine vorgefertigten Datensätze verwendet.
Denn die Generierung eigener Bilder erlaubt eine größere Kontrolle über Eigenschaften der Bilder und Inhalte, als vorgefertigte Sets.
Damit trotzdem eine Vergleichbarkeit zu anderen Arbeiten gewährleistet werden kann, wird die Generierung deterministisch reproduzierbar und dokumentiert sein.

\newcommand{\trainDataImage}[1]{\subfloat{\fbox{\includegraphics[width=.29\linewidth]{#1}}}}
\begin{figure}
	\trainDataImage{kapitel/3\_methodik/data/circle\_00.png}\hfill
	\trainDataImage{kapitel/3\_methodik/data/circle\_01.png}\hfill
	\trainDataImage{kapitel/3\_methodik/data/circle\_02.png}\par \hfill
	
	\trainDataImage{kapitel/3\_methodik/data/rectangle\_00.png}\hfill
	\trainDataImage{kapitel/3\_methodik/data/rectangle\_01.png}\hfill
	\trainDataImage{kapitel/3\_methodik/data/rectangle\_02.png}\par \hfill
	
	\trainDataImage{kapitel/3\_methodik/data/triangle\_00.png}\hfill
	\trainDataImage{kapitel/3\_methodik/data/triangle\_01.png}\hfill
	\trainDataImage{kapitel/3\_methodik/data/triangle\_02.png}\par \hfill
	
	\caption{Zufällig generierte Trainingsbilder}
\end{figure}

\subsection{Bildeigenschaften}
Auch die Bildeigenschaften sind ein wichtiger Bestandteil des Datensatzes.
Mit Bildeigenschaften sind dabei nicht Inhalte, sondern allgemeinere Merkmale gemeint.
Durch die Merkmale werden vor allem die benötigten Rechenkapazitäten zum Trainieren des GANs beeinflusst.
So können Trainingszeiten durch kleinere Bilder verkürzt werden, da mehr Bilder auf einmal in den Grafikspeicher der GPU geladen werden können.
Als Folge können mehr Konfigurationen ausprobiert werden
Die Qualität der Bilder muss allerdings immer hoch genug bleiben, dass eine Erkennbarkeit der Formen gewährleisten ist.

\begin{description}
	\item[Farbe]
	Die Bilder sind grau-skaliert, das heißt ein Pixel entspricht einer Zahl zwischen 0 (schwarz) und 255 (weiß).
	
	\item[Größe]
	Alle Bilder benötigen die gleiche Größe, um zur späteren GAN-Architektur zu passen.
	Damit die geometrischen Formen auch erkennbar sind, dürfen sie jedoch nicht zu klein sein, wohingegen zu große Bilder Trainingszeiten unnötig verlängern.
	Die Bilder sind 64x64 Pixel groß, was einen Kompromiss darstellt.
\end{description}

\subsection{Eigenschaften der Figuren}
Die Trainingsbilder für das GAN stellen jeweils eine geometrische Form dar.
Bei den Formen handelt es sich um Kreise, Dreiecke und Rechtecke, die von Bild zu Bild unterschiedlich sind.
Die Bilder unterscheiden sich in mehreren Aspekten:
\begin{description}[style=nextline]
	\item[Position]
	Die Formen sind zufällig auf dem Bild positioniert.
	Allerdings sind sie immer vollständig abgebildet, das heißt, die Kanten des Bildes schneiden die Form nicht.
	%Formen erstrecken sich nicht über Ränder und erscheinen auf der anderen Seite wieder?
	Je nach Größe der Form muss so die Position treffend gewählt werden.
	
	\item[Größe und Form]
	Die Formen sind unterschiedlich groß, besitzen aber eine minimale und maximale Größe.
	So ist gewährleistet, dass Bilder nicht einfarbig erscheinen und die Form immer erkennbar bleibt.
	
	Während sich Rechtecke durch unterschiedliche Seitenlängen stark voneinander unterscheiden können, werden Dreiecke und Kreise unter gleichbleibenden Seitenverhältnissen skaliert.
\end{description}


\section{Training}
Der Vergleich von GANs ist ein schwieriges Unterfangen \cite{are-gans-created-equally}.
So gibt es nicht nur viele sehr sensible Konfigurationsmöglichkeiten, sie beeinflussen sich auch gegenseitig.
Zudem starten Neuronale Netze vor dem Training in der Regel in einem zufälligen Ausgangszustand, weswegen auch gleiche Trainingsbedingungen zu leicht unterschiedlichen Resultaten führen können.
Im Folgenden werden die Schwierigkeiten und angewendete 'Lösungen' für einen möglichst objektiven Vergleich aufgezeigt.

\subsection{Vorauswahl von Hyperparamtern}
Zunächst ist anzumerken, dass es nicht möglich ist, alle Konfigurationen durchzuprobieren.
Dafür würden zu hohe Rechenkapazitäten benötigt, die selbst große Unternehmen wie Google nicht immer aufbieten wollen/können \cite{are-gans-created-equally}.
Deshalb muss eine 'sinnvolle' Vorauswahl an Konfigurationen getroffen werden, wodurch das Ergebnis schon einer gewissen Voreingenommenheit unterliegt.
Somit wird die finale Entscheidung für die (möglichst) optimalen Konfigurationen des GANs immer subjektiv geprägt sein.

\subsection{Analyse von Hyperparametern}
Einige Hyperparameter können auch systematisch bestimmt werden.
Dabei handelt es sich um die Lossfunction, Learning Rate und Number of Units.
Mithilfe dieser 3 Hyperparameter soll dann der Trainingserfolg analyiert werden.

\section{Erfolgskriterien}
Damit die Konfigurationen treffend vorausgewählt werden könne, müssen die Kriterien für ein erfolgreich trainiertes GAN klar definiert werden.
Als Erfolgskriterien zählen in diesem Fall die Varietät der generierten Bilder und die Korrektheit der generierten Figuren.
Beide Kriterien werden im Folgenden noch einmal genauer erläutert.

\paragraphNewLine{Varietät}
Die Varietät bezieht zum einen auf die Ähnlichkeit zwischen Trainingsbildern und den generierten Bildern der GANs.
Die Ähnlichkeit zwischen diesen beiden Bildersets beschreibt, wie gut das GAN 'etwas neues schaffen' kann, oder ob es nur Trainingsbilder dupliziert.
Sollte die Ähnlichkeit sehr gering sein, werden viele 'neue' Bilder generiert, was sehr positiv zu bewerten ist.
Zudem bezieht sich die Varietät auf die generierten Bilder untereinander.
Sie sollten auch möglichst verschieden sein, was oftmals nicht der Fall ist.
Das Phänomen ist als 'mode-collapse' bekannt (siehe Stand der Technik). %TODO steht das auch in Stand der Technik?

Beide Probleme lassen sich durch den Vergleich der Bilder mittels 'Structural Similarity Index' \cite{structural-similarity-index} bewerten.
% https://scikit-image.org/docs/0.12.x/api/skimage.measure.html#skimage.measure.compare_ssim

\paragraphNewLine{Korrektheit}
Neben der Varietät besitzt auch die Korrektheit eine hohe Bedeutung für die Bewertung der GANs.
Dabei muss sichergestellt werden, dass die richtige Figur generiert wurde und erkennbar ist.
Die Figuren müssen außerdem den gleichen Kriterien wie die Trainingsdaten genügen, das heißt, die Figuren sollten zum Beispiel vollständig innerhalb des Bildes abgebildet sein.
Es ist allerdings eher unwahrscheinlich, dass das GAN Bilder generiert, die keinem Pendant aus den Trainingsbildern entsprechen.
Ein weiterer wichtiger Aspekt der Bilder ist das Verhalten im Hintergrund der Figur.
So sollten im Hintergrund möglichst keine anderen Figuren oder Pixelfragmente erzeugt werden.

All diese Kriterien werden durch eine manuelle Überprüfung evaluiert werden.

\begin{itemize}
	\item Inception Score zum Rating von erzeugten Bildern (Salimans et al. 2016)
	\item Frechet Inception Distance (Heusel et al. 2017)
\end{itemize}

\section{Verfahren zur Hyperparametersuche}
Zur Auswahl von Hyperparametern gibt es verschiedene Verfahren.
Dazu gehören unter anderem die Manuelle Suche, Gridsearch, Random Search und Genetic Algorithms.
Die Verfahren sind jeweils im Stand der Technik erklärt (siehe \cref{chapter:verfahrenBestimmungHyperparameter}).
In diesem Abschnitt werden die verschiedenen Verfahren verglichen und zusätzliche Anpassungen erläutert.

\subsection{Vergleich}
In der Studienarbeit wird ausschließlich die Gridsearch zur Bestimmung der Hyperparameter zur Anwendung kommen.
Die Entscheidung ist mit den nachfolgenden Punkten begründet.

\paragraphNewLine{Manuelle Suche}
Die ausschließlich manuelle Suche ist zwar sehr flexibel \todo{anderes wort}, aber zu aufwändig.
Eine weitreichende Suche mit ständiger Neuevaluierung der Trainingsergebnisse ist für den kurzen Zeitraum der Studienarbeit nicht verhältnismäßig.
Zudem ist das Verfahren für eine komplexe Hyperparametersuche nicht mehr zeitgemäß.
Die anderen vorgestellten Verfahren sind der manuellen Suche immer überlegen.

\paragraphNewLine{Zufallssuche}
Die Zufallssuche ist der Gridsearch sehr ähnlich.
Statt festgelegten Zahlen werden Zufallszahlen verwendet.
Dadurch wird ein größeres Spektrum an Kombinationen abgedeckt.
Allerdings führt das Verfahren in der Praxis nicht unbedingt zu besseren Ergebnissen als die Gridsearch.
Zusätzlich führt es zu einem größeren Implementierungsaufwand und wieder mehr Hyperparametern als die Gridsearch.
Der erhöhte Implementierungsaufwand ist durch eine zusätzliche Zufallsfunktion zu begründen.
Die Funktion wird benötigt, um die alle Kombinationen anzupassen.
Im Vergleich dazu kann bei der Gridsearch pro Hyperparameter ein Array mit verschiedenen Werten übergeben werden.
Die zusätzlichen Hyperparameter hängen auch mit der Zufallsfunktion zusammen.
Denn der zufällige Abstand zum Originalwert muss in einem sinnvollen Intervall liegen.
Die Bestimmung der Grenzen des Intervalls benötigt zusätzliche Anpassungen und Training.

\paragraphNewLine{Evolutionäre Suche}
Die evolutionäre Suche ist sowohl mit einem hohen Implementierungs-, als auch Rechenaufwand verbunden.
Dafür ist es möglich, sehr viele Hyperparameter auf ihre Zusammenhänge zu untersuchen.
Jedoch reduzieren wir die Hyperparameter auf eine kleine Auswahl, weswegen der Aufwand nicht gerechtfertigt ist.

\paragraphNewLine{Gridsearch}
Die Gridsearch ist für die Arbeit am besten geeignet, da sie zum einen einen sehr geringen Implementierungsaufwand mit sich bringt.
Es müssen nur die Hyperparameter festgelegt werden, der Suchprozess kann dann mithilfe von Tensorboard grafisch veranschaulicht werden.

\subsection{Anpassung an Gridsearch}
Zwar findet die Gridsearch in keiner intelligenten Weise die optimalen Hyperparameter, aber durch kurze Trainings- und Validierungsintervalle können schlecht trainierende Kombinationen schnell aussortiert werden.
Dafür können am Anfang $n$ GANs auf $m$ Generationen trainiert werden.
Nach dem Training werden die Ergebnisse evaluiert und die Hälfte der GANs aussortiert 
Im Gegenzug wird die Anzahl der zu trainierenden Generationen verdoppelt.
So bleibt der Aufwand für das Training, bei deutlich erhöhter Intensität, der gleiche.
Es ist anzumerken, dass die neuronalen Netze weitertrainiert werden und der vorhandene Lernfortschritt nicht zurückgesetzt wird.
Der Prozess wird beliebig oft wiederholt und es können zu jedem Zeitpunkt Zusammenhänge zwischen den verbliebenen GANs analysiert werden.





\begin{comment}

Die Korrektheit bezieht sich dabei auf die generierte Figur im Bild oder auch umliegende Bildpunkte.
Für die Korrektur der richtigen Formen gibt es mehrere Möglichkeiten:
\begin{description}
	\item[Neuronales Kontrollnetz]
	Dafür wird ein weiteres Netzwerk zur Bewertung der Resultate trainiert.
	Diese Variante ist sehr ungenau, da sie wieder von dem Trainingserfolg eines Neuronalen Netzes abhängt.
	Allerdings erlaubt das Neuronale Netzwerk die Analyse von großen Datensätzen, die aber in diesem Fall nicht in der Form nötig sein wird.
	
	\item[händisch]
	Das händische Kontrollieren ist sehr aufwändig.
	Für die Kontrolle sollte das aber möglich sein.
	
	\item[Formvergleich]
	Es ist möglich, die Lösung zu brute-forcen.
	Das bedeutet, es wird jede mögliche Form über das Bild gelegt und diejenige mit der höchsten Überschneidung ausgewählt und als Indikator genommen.
\end{description}



\section{GAN: Bewertungs- und Vergleichskriterien}

% How to write methods section: http://rc.rcjournal.com/content/respcare/49/10/1229.full.pdf
\subsection{Warum synthetische Daten?}
Mehr Kontrolle über die Bilder:
\footnote{Die meisten Anpassungen erlauben auch Rechenleistung zu reduzieren, falls Computer überlastet sein sollten.}
\begin{enumerate}
	\item Anpassung von Größe
	\item Anzahl der unterschiedlichen labels (wieviel unterschiedliche Formen sind enthalten)
	\item sich unterscheidende Features in den Bildern (wo genau sind die Bilder zu finden, unterschiedliche Größe, Rotation?)
	\item wie generiert? $\rightarrow$ Deterministisch $\rightarrow$ Seed
	\item weniger Arbeitsaufwand als händische Generierung
\end{enumerate}

\subsection{Welche Eigenschaften haben die Bilder genau?}
\begin{enumerate}
	\item größe: 28x28
	\item farbe: 1-dimensional $\rightarrow$ scharz-weiß 
\end{enumerate}

\section{Training}
Ziel: GAN das möglichst diverse und korrekte Bilder erzeugt $\rightarrow$ Wie wird das erreicht?
\begin{enumerate}
	\item Anpassung von Hyperparametern (Learning-rate, batch-size, momentum)
	\footnote{https://towardsdatascience.com/what-are-hyperparameters-and-how-to-tune-the-hyperparameters-in-a-deep-neural-network-d0604917584a}
	\footnote{Grid-search (erlaubt methodisches Suchen nach optimalen Hyperparametern): https://www.tensorflow.org/tensorboard/hyperparameter\_tuning\_with\_hparams}
	\item Anpassung von Neuralen Netzarchitektur
	\footnote{https://lab.wallarm.com/the-first-step-by-step-guide-for-implementing-neural-architecture-search-with-reinforcement-learning-using-tensorflow-99ade71b3d28/}
\end{enumerate}

\section{Bewertung bzw. Vergleich der GANs}
Ziel: messbare Vergleichskriterien

\subsection{Korrektheit der Bilder}
\begin{enumerate}
	\item richtige Form für das angegebene Label? 
	\item muss per Hand bestimmt werden? oder festen algorithmus, der form erkennt? neuronales netz wäre zu ungenau?
\end{enumerate}

\subsection{Diversität der generierten Bilder}
\begin{enumerate}
	\item Vergleich zu Trainingsdaten (wird etwas neues geschaffen?)
	\item Vergleich zu anderen generierten Bildern $\rightarrow$ (Parital) Mode-Collapse?
	\footnote{https://developers.google.com/machine-learning/gan/problems}
	\footnote{eventuell 2 discriminator?: https://dl.acm.org/doi/10.1145/3283254.3283282}
	\footnote{Google: https://research.google/pubs/pub45829/}
	
	\item Vergleich von Bildern durch 'Pixel by Pixel' Ähnlichkeit bestimmen $\rightarrow$ die X bilder mit einer Ähnlichkeit über Y \% können dann angeguckt werden
\end{enumerate}
\end{comment}